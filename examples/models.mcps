// Example: Model Configuration
// This demonstrates how to declare LLMs in MCP Script
//
// NOTE: To run this example with API-based providers, set environment variables:
//   export OPENAI_API_KEY=your-key-here
//   export ANTHROPIC_API_KEY=your-key-here
//   export GOOGLE_API_KEY=your-key-here
//
// Or use a local model through Ollama

// OpenAI model with API key from environment
model gpt4 {
  provider: "openai",
  model: "gpt-5.1-2025-11-13",
  apiKey: env.OPENAI_API_KEY,
  temperature: 0.5
}

// Anthropic Claude model
model claude {
  provider: "anthropic",
  model: "claude-sonnet-4-5",
  apiKey: env.ANTHROPIC_API_KEY,
  temperature: 0.5
}

// Google Gemini model
model gemini {
  provider: "gemini",
  model: "gemini-2.5-pro",
  apiKey: env.GOOGLE_API_KEY,
  temperature: 0.5
}

// Local Ollama model
model gptoss {
  provider: "openai",
  apiKey: "ollama",
  baseURL: "http://localhost:11434/v1",
  model: "gpt-oss:20b",
  temperature: 0.5
}
